+++
title = "Statistics"
author = ["Cash Prokop-Weaver"]
date = 2022-12-24T15:05:00-08:00
lastmod = 2023-07-25T12:31:04-07:00
tags = ["has-todo", "concept", "has-todo", "concept"]
categories = ["has-todo", "concept"]
draft = false
slug = "a55b6c56-64e8-4349-9c27-555217caeb91"
+++

## Flashcards {#flashcards}


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.65 | 9   | 609.04   | 2025-03-04T20:17:30Z |
| back     | 2.65 | 8   | 180.26   | 2023-05-07T22:15:45Z |

\\(Y = f(X) + \epsilon\\)


#### Back {#back}

A model that captures the relationship between \\(Y\\) and \\(X\\)


#### Extra {#extra}

-   \\(Y\\): Output
-   \\(X\\): Input
-   \\(f\\): Fixed, but often unknown, function
-   \\(\epsilon\\): Random error term with mean 0; the irreducible error


#### Source {#source}

(<a href="#citeproc_bib_item_18">James et al. 2013</a>)


### k-means is a {{heuristic}{optimality}@0} {#k-means-is-a-heuristic-optimality-0}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 9   | 300.87   | 2024-01-08T11:59:29Z |


#### Extra {#extra}


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### The clustering objective function provided in VMLS: {{\\(J\_{\text{clust} } = \frac{1}{n} \sum \\| \vec{x}\_i - \vec{z}\_{\vec{c}\_i}\\|^2\\)}@0} {#the-clustering-objective-function-provided-in-vmls-j-text-clust-frac-1-n-sum-vec-x-i-vec-z-vec-c-i-2-0}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.05 | 3   | 6.00     | 2022-11-16T16:24:14Z |


#### Extra {#extra}

Where

1.  \\(\vec{x} \in X\\) and \\(X\\) is the set of vectors we are clustering
2.  \\(\vec{c}\\) is the vector whose \\(i\text{-th}\\) value indicates the cluster to which \\(\vec{x}\_i\\) belongs
3.  \\(\vec{z}\\) is the vector of centroids


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### We try to estimate \\(f\\) in \\(Y = f(X) + \epsilon\\) to {{predict}@0} and {{infer}@1}. {#we-try-to-estimate-f-in-y-f--x--plus-epsilon-to-predict-0-and-infer-1-dot}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 1        | 2.65 | 3   | 6.00     | 2022-12-07T16:04:04Z |
| 0        | 2.65 | 3   | 6.00     | 2022-12-08T22:00:14Z |


#### Extra {#extra}


#### Source {#source}

(<a href="#citeproc_bib_item_18">James et al. 2013</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 10  | 364.32   | 2024-03-12T22:11:26Z |
| front    | 2.05 | 1   | 1.00     | 2023-06-30T20:52:40Z |

Expected value


#### Back {#back}

The mean of a large number of independent realizations of a random variable.


#### Source {#source}

(<a href="#citeproc_bib_item_16">“Expected Value” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 435.10   | 2024-05-27T19:59:26Z |
| 1        | 2.65 | 8   | 466.75   | 2024-07-13T09:18:34Z |

-   {{\\(E[X]\\)}@0}

{{The expected value of a random variable, \\(X\\).}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_16">“Expected Value” 2022</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.35 | 8   | 233.32   | 2023-08-07T01:23:06Z |
| back     | 2.50 | 8   | 250.69   | 2023-10-09T07:11:20Z |

Irreducible error


#### Back {#back}

Error term based on the assumption that we do not and never can have all of the data; you can't simulate the universe.


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.65 | 8   | 396.46   | 2024-04-15T02:15:05Z |
| back     | 2.50 | 10  | 271.93   | 2023-11-17T15:42:52Z |

Reducible error


#### Back {#back}

The difference between \\(f\\) and \\(\hat{f}\\).


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 12  | 372.71   | 2024-03-24T07:19:21Z |
| 1        | 2.50 | 5   | 33.54    | 2023-08-14T02:04:36Z |
| 2        | 1.40 | 5   | 12.23    | 2023-03-31T23:01:46Z |
| 3        | 2.95 | 6   | 118.16   | 2023-04-15T22:27:24Z |
| 4        | 2.80 | 6   | 148.87   | 2023-07-29T11:20:25Z |

-   {{Input variable}@0}
-   {{Predictor}@1}
-   {{Independent variable}@2}
-   {{Feature}@3}
-   {{Covariate}@4}


#### Source {#source}


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 12  | 464.02   | 2024-08-28T14:15:32Z |
| 1        | 2.65 | 9   | 530.05   | 2024-11-19T17:10:03Z |
| 2        | 2.35 | 1   | 1.00     | 2023-07-16T14:19:16Z |
| 3        | 2.35 | 8   | 232.40   | 2023-08-07T13:14:23Z |
| 4        | 2.65 | 9   | 292.31   | 2023-12-20T21:22:44Z |

-   {{Objective function}@0}
-   {{Loss function}@1}
-   {{Cost function}@2}
-   {{Energy function}@3}
-   {{Reward function}@4}


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.80 | 10  | 290.15   | 2023-10-20T20:13:49Z |
| 1        | 2.20 | 7   | 165.75   | 2023-09-13T09:28:23Z |
| 2        | 2.80 | 8   | 281.02   | 2023-12-02T04:15:26Z |

-   {{Output variable}@0}
-   {{Response}@1}
-   {{Dependent variable}@2}


#### Source {#source}


### Algorithm {#algorithm}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.50 | 0   | 0.00     | 2022-09-21T15:37:30Z |
| back     | 2.5  | -1  | 0        | 2022-01-01T13:00:00Z |

k-means clustering


#### Back {#back}

**Setup**

Given:

1.  A list of \\(n\\) vectors, \\(\vec{x}\_1 \dots \vec{x}\_n\\)
2.  An initial list of \\(k\\) group representative vectors, \\(\vec{z}\_i \dots \vec{z}\_k\\)

Where:

1.  \\(\vec{c}\\) encodes cluster membership
2.  \\(\vec{c}\_i\\) indicates the cluster to which \\(\vec{x}\_i\\) belongs.

Follow these steps:

1.  Initialize the centroids

    \\(\vec{\mu}\_i \dots \vec{\mu}\_k\\)

    Repeat until convergence:

2.  Partition the vectors into \\(k\\) groups\*

    For each vector, assign \\(\vec{x}\_i\\) to the group associated with the nearest representative.\\(\vec{c}\_i := \underset{j}{\operatorname{argmin} } \\| \vec{x}\_i - \vec{\mu}\_j \\|^2\\) for \\(i = 1 \dots n\\), \\(j = 1 \dots k\\)

3.  Update representatives\*

    For each group, set \\(\vec{z}\_i\\) to be the mean of the vectors in the $i$th group.\\(\vec{\mu}\_j := \frac{\sum\_{i=1}^{n} 1\\{\vec{c}\_i = j\\}\vec{x}\_i}{\sum\_{i=1}^{n} 1\\{\vec{c}\_i = j\\} }\\) for \\(j = 1 \dots k\\)


#### Source {#source}

(<a href="#citeproc_bib_item_19">“K-Means Clustering” 2022</a>)


### Cloze (Math) {#cloze--math}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 4   | 14.00    | 2023-07-17T00:54:44Z |

Clusters are represented by {{representative vectors}@0}.


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### Representative vectors, \\(z\_i\\), of a cluster are calculated by minimizing {{\\(\sum \\| x\_i - z\_i \\| \\; \forall \\; x\_i \in \text{Cluster}\\)}{expression}@0} {#representative-vectors-z-i-of-a-cluster-are-calculated-by-minimizing-sum-x-i-z-i-forall-x-i-in-text-cluster-expression-0}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.05 | 3   | 6.00     | 2022-11-24T16:07:55Z |


#### Extra {#extra}


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### Definition (Statistics, ML) {#definition--statistics-ml}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.50 | 10  | 425.62   | 2024-06-10T07:07:12Z |
| front    | 2.65 | 8   | 463.97   | 2024-07-15T13:52:52Z |

Clustering


#### Back {#back}

The task of grouping a set of objects in such a way that elements in the same group are more similar to each other than to those in other groups.


#### Source {#source}

(<a href="#citeproc_bib_item_10">“Cluster Analysis” 2022</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.65 | 8   | 336.13   | 2024-01-28T19:04:08Z |
| back     | 2.65 | 8   | 232.07   | 2023-07-15T16:52:35Z |

\\(\hat{Y} = \hat{f}(\hat{X})\\)


#### Back {#back}

A model which represents our predictions, \\(\hat{Y}\\), based on our estimate of \\(f\\), \\(\hat{f}\\), on the input data, \\(\hat{X}\\).


#### Extra {#extra}

The value \\(\epsilon\\) is not included as we cannot influence/reduce the irreducible error.


#### Source {#source}

(<a href="#citeproc_bib_item_18">James et al. 2013</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.65 | 10  | 416.35   | 2024-06-01T00:35:31Z |
| back     | 2.65 | 9   | 472.79   | 2024-08-31T09:51:42Z |

Odd function


#### Back {#back}

-   \\(\overset{\Delta}{=}\\) \\(-f(x) = f(-x)\\)
-   Geometrically, they have rotational symmetry with respect to the origin (the graph remains unchanged when rotated 180 degrees about the origin).
-   Examples: \\(x\\), \\(x^3\\), \\(sin(x)\\)


### Example(s) {#example--s}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.50 | 7   | 174.69   | 2023-10-09T08:30:31Z |
| back     | 2.65 | 7   | 130.45   | 2023-04-13T06:29:01Z |

Asymptote


#### Back {#back}

-   The \\(x\\) and \\(y\\) axis for \\(f(x) = \frac{1}{x}\\)


#### Source {#source}

(<a href="#citeproc_bib_item_2">“Asymptote” 2022</a>)


### {{\\(\operatorname{P}(A)\\)}@0} \\(=\\) {{\\(\sum\_i \operatorname{P}(A \cap B\_i)\\)}{total}@1} {#operatorname-p--a--0-sum-i-operatorname-p--a-cap-b-i--total-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 5   | 35.97    | 2023-08-29T03:16:17Z |
| 1        | 2.35 | 7   | 181.95   | 2023-10-08T14:28:50Z |


#### Source {#source}

(<a href="#citeproc_bib_item_20">“Law of Total Probability” 2022</a>)


### Definition {#definition}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.50 | 8   | 353.10   | 2024-03-04T16:33:56Z |
| front    | 2.50 | 8   | 242.81   | 2023-08-30T12:18:58Z |

Time series


#### Back {#back}

A series of data points indexed in time-order.


#### Source {#source}

(<a href="#citeproc_bib_item_41">“Time Series” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.35 | 9   | 319.67   | 2024-02-03T08:24:41Z |
| front    | 2.65 | 7   | 141.48   | 2023-04-05T03:52:01Z |

Base rate


#### Back {#back}

Indicate probability based on the absence of other information. Describes the percentage of a population that demonstrates some characteristic.


#### Source {#source}

(<a href="#citeproc_bib_item_3">“Base Rate” 2022</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.50 | 8   | 295.23   | 2023-11-03T20:11:19Z |
| back     | 2.35 | 9   | 321.47   | 2024-02-02T01:26:46Z |

Confusion matrix


#### Back {#back}

-   A \\(N\times N\\) matrix which describes the performance of an algorithm.
-   Rows correspond to predicted classes.
-   Columns correspond to actual classes.
-   Numbers along the main diagonal correspond to correct predictions; everything else corresponds to incorrect predictions.


#### Source {#source}

(<a href="#citeproc_bib_item_12">“Confusion Matrix” 2022</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.50 | 9   | 334.21   | 2024-01-17T06:45:12Z |
| back     | 2.80 | 10  | 363.60   | 2024-02-27T18:34:35Z |

Non-parametric models


#### Back {#back}

-   Doesn't make explicit assumptions about the functional form of \\(f\\) in \\(Y = f(X) + \epsilon\\)
-   Complexity is unbounded given unbounded data
-   More data often implies more parameters


#### Extra {#extra}

eg: k-nearest neighbors, support vector machines


#### Source {#source}

(<a href="#citeproc_bib_item_18">James et al. 2013</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.65 | 9   | 378.59   | 2024-04-03T07:37:17Z |
| back     | 2.65 | 8   | 419.39   | 2024-08-23T10:52:03Z |

Parametric models


#### Back {#back}

-   Make explicit assumptions about the functional form of \\(f\\) in \\(Y = f(X) + \epsilon\\).
-   Complexity is bounded given unbounded data.
-   All information about the predictions are encoded in the parameters.


#### Extra {#extra}

eg: Logistic regression


#### Source {#source}

(<a href="#citeproc_bib_item_18">James et al. 2013</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.80 | 9   | 375.78   | 2024-03-12T09:03:23Z |
| back     | 2.80 | 9   | 373.50   | 2024-03-12T03:18:42Z |

The probability space of rolling a d6


#### Back {#back}

Sample space: \\(\\{1, 2, 3, 4, 5, 6\\}\\)

Event space: \\(\\{\\{1\\}, \dots, \\{6\\}, \\{1, 2, 3\\}, \\{2, 4, 6\\}, \dots\\}\\)

Probability function: \\(f(\text{event}) = \operatorname{card}(\text{event}) / 6\\)


#### Source {#source}

(<a href="#citeproc_bib_item_29">“Probability Space” 2022</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.50 | 8   | 281.14   | 2023-11-05T19:43:48Z |
| back     | 2.35 | 6   | 71.78    | 2023-08-01T07:37:35Z |

Why Bessel's correction is used


#### Back {#back}

The goal is to reduce the bias due to a finite sample size. The bias is more significant at smaller sample sizes.


#### Source {#source}

(<a href="#citeproc_bib_item_5">“Bessel’s Correction” 2022</a>)


### Example(s) {#example--s}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.80 | 8   | 334.15   | 2024-01-24T07:19:20Z |
| back     | 2.35 | 8   | 192.12   | 2023-06-23T21:15:51Z |

Parametric model


#### Back {#back}

-   \\(y = mx + b\\); parameterized by \\(m\\) and \\(b\\)
-   Logistic regression


#### Source {#source}

(<a href="#citeproc_bib_item_17">Ghahramani, n.d.</a>)


### {{\\(n\operatorname{stddev}(\vec{a} + \vec{b})^2\\)}{function}@0} \\(=\\) {{\\(\\|\mathbf{C}\vec{a} + \mathbf{C}\vec{b}\\|^2\\)}{norm}@1} {#n-operatorname-stddev--vec-a-plus-vec-b--2-function-0-mathbf-c-vec-a-plus-mathbf-c-vec-b-2-norm-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 5   | 41.47    | 2023-01-11T03:58:37Z |
| 1        | 2.65 | 5   | 45.73    | 2022-11-29T09:16:39Z |


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### {{\\(n\operatorname{stddev}(\vec{a} + \vec{b})^2\\)}{function}@0} \\(=\\) {{\\(\\|\mathbf{C}\vec{a}\\|^2 + 2(\mathbf{C}\vec{a})^\textsf{T}(\mathbf{C}\vec{b}) + \\|\mathbf{C}\vec{b}\\|^2\\)}{distributed}@1} {#n-operatorname-stddev--vec-a-plus-vec-b--2-function-0-mathbf-c-vec-a-2-plus-2--mathbf-c-vec-a--textsf-t--mathbf-c-vec-b--plus-mathbf-c-vec-b-2-distributed-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 5   | 37.74    | 2022-12-26T09:56:03Z |
| 1        | 2.50 | 1   | 1.00     | 2022-11-20T15:55:43Z |


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### {{\\(n\operatorname{stddev}(\vec{a} + \vec{b})^2\\)}{function}@0} \\(=\\) {{\\(n\operatorname{stddev}(\vec{a})^2\\) \\(+\\) \\(2n\rho\_{\vec{a}, \vec{b}}\operatorname{stddev}(\vec{a})\operatorname{stddev}(\vec{b})\\) \\(+\\) \\(n\operatorname{stddev}(\vec{b})^2\\)}{distributed functions}@1} {#n-operatorname-stddev--vec-a-plus-vec-b--2-function-0-n-operatorname-stddev--vec-a--2-plus-2n-rho-vec-a-vec-b-operatorname-stddev--vec-a--operatorname-stddev--vec-b--plus-n-operatorname-stddev--vec-b--2-distributed-functions-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 1   | 1.00     | 2022-11-27T14:55:29Z |
| 1        | 2.5  | -1  | 0        | 2022-01-01T13:00:00Z |


#### Source {#source}

(<a href="#citeproc_bib_item_9">Boyd and Vandenberghe 2018</a>)


### {{\\(\operatorname{avg}(\vec{x})\\)}{function}@0} \\(=\\) {{\\(\frac{1}{n} \sum \vec{x}\_i\\)}{summation}@1} {#operatorname-avg--vec-x--function-0-frac-1-n-sum-vec-x-i-summation-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.95 | 7   | 347.08   | 2024-01-31T19:17:23Z |
| 1        | 2.80 | 7   | 362.47   | 2024-03-07T16:34:58Z |


### {{\\(\operatorname{avg}(\vec{x})\\)}{function}@0} \\(=\\) {{\\(\frac{1}{n} (\vec{1} \cdot \vec{x})\\)}{vector}@1} {#operatorname-avg--vec-x--function-0-frac-1-n--vec-1-cdot-vec-x--vector-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 7   | 187.77   | 2023-08-07T08:54:20Z |
| 1        | 2.35 | 7   | 239.25   | 2023-11-04T09:19:33Z |


### {{\\(\operatorname{rms}(\vec{x})\\)}{function}@0} \\(=\\) {{\\(\operatorname{avg}(\vec{x})\\) \\(+\\) \\(\operatorname{stddev}(\vec{x})\\)}{functions}@1} {#operatorname-rms--vec-x--function-0-operatorname-avg--vec-x--plus-operatorname-stddev--vec-x--functions-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.05 | 8   | 168.20   | 2023-11-05T17:45:08Z |
| 1        | 2.20 | 7   | 101.58   | 2023-05-10T06:44:26Z |


#### Source {#source}

(<a href="#citeproc_bib_item_32">“Root Mean Square” 2022</a>)


### {{\\(\operatorname{rms}(\vec{x})\\)}{function}@0} \\(=\\) {{\\(\sqrt{\operatorname{ms}(\vec{x})}\\)}{function}@1} {#operatorname-rms--vec-x--function-0-sqrt-operatorname-ms--vec-x--function-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 7   | 188.58   | 2023-07-28T07:13:45Z |
| 1        | 2.80 | 7   | 245.03   | 2023-10-18T05:32:39Z |


#### Source {#source}

(<a href="#citeproc_bib_item_32">“Root Mean Square” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.35 | 11  | 307.64   | 2024-01-01T20:14:37Z |
| front    | 2.50 | 8   | 240.91   | 2023-08-28T14:26:55Z |

Random variable


#### Back {#back}

A variable whose values depend on outcomes of a random phenomenon.

Formally: A measurable function defined on a probability space that maps from the sample space to \\(\mathbb{R}\\).


#### Source {#source}

(<a href="#citeproc_bib_item_30">“Random Variable” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.80 | 7   | 182.58   | 2023-05-28T04:30:51Z |
| front    | 2.80 | 7   | 197.15   | 2023-07-07T19:07:09Z |

Residual sum of squares


#### Back {#back}

The sum of squares of residuals (differences between predicted and observed data).


#### Extra {#extra}

\\(\text{RSS} = \sum^{n}\_{i=1}(f(x\_i) - \hat{f}(x\_i))^2\\)


#### Source {#source}

(<a href="#citeproc_bib_item_31">“Residual Sum of Squares” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.35 | 9   | 331.74   | 2024-02-24T08:35:44Z |
| front    | 2.65 | 8   | 323.78   | 2024-01-20T10:49:47Z |

Sample space of a probability space


#### Back {#back}

The set of all possible outcomes.


#### Source {#source}

(<a href="#citeproc_bib_item_29">“Probability Space” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.00 | 6   | 45.41    | 2023-08-22T10:09:29Z |
| front    | 2.00 | 7   | 120.28   | 2023-09-14T19:10:16Z |

Sampling distribution


#### Back {#back}

The probability distribution of a given random-sample-based statistic.


#### Extra {#extra}

eg: Normal distribution: \\(\mathcal{N}(\mu, \sigma^2)\\)


#### Source {#source}

(<a href="#citeproc_bib_item_34">“Sampling Distribution” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.45 | 13  | 350.16   | 2024-04-13T02:27:16Z |
| front    | 2.35 | 6   | 84.70    | 2023-10-01T07:47:16Z |

Simple linear regression


#### Back {#back}

A linear regression model with a single explanatory variable.


#### Extra {#extra}

\\(\hat{Y} = \hat{f}(x) = \hat{\beta\_0} + \hat{\beta\_1}x\\)


#### Source {#source}

(<a href="#citeproc_bib_item_35">“Simple Linear Regression” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.20 | 16  | 247.18   | 2023-10-05T18:55:53Z |
| front    | 1.90 | 1   | 1.00     | 2023-07-17T13:58:06Z |

Standard error


#### Back {#back}

The standard deviation of a statistic's sampling distribution.


#### Source {#source}

(<a href="#citeproc_bib_item_37">“Standard Error” 2022</a>)


### Definition (Math) {#definition--math}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 8   | 335.06   | 2024-02-09T06:39:48Z |
| front    | 2.20 | 8   | 221.95   | 2023-10-04T02:28:59Z |

Statistic


#### Back {#back}

A quantity computed from values in a sample.


#### Source {#source}

(<a href="#citeproc_bib_item_39">“Statistic” 2022</a>)


### Definition (Math) {#definition--math}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.50 | 10  | 408.14   | 2024-06-13T03:05:07Z |
| front    | 2.80 | 9   | 539.32   | 2025-01-03T20:44:04Z |

Stochastic


#### Back {#back}

Any randomly determined process.


#### Source {#source}

(<a href="#citeproc_bib_item_40">“Stochastic” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.80 | 8   | 375.51   | 2024-02-26T04:09:42Z |
| front    | 2.65 | 8   | 302.57   | 2023-12-23T17:47:41Z |

Unbiased estimator


#### Back {#back}

An estimator with zero bias; neither overestimates, nor underestimates, the true expected value.


#### Source {#source}

(<a href="#citeproc_bib_item_6">“Bias of an Estimator” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 10  | 462.79   | 2024-08-06T18:03:23Z |
| front    | 2.80 | 8   | 338.85   | 2024-01-23T15:06:11Z |

Underfitting


#### Back {#back}

A descriptor of a statistical model which cannot adequately capture the underlying structure of the data.


#### Source {#source}

(<a href="#citeproc_bib_item_26">“Overfitting” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 8   | 413.29   | 2024-06-15T21:13:21Z |
| front    | 2.65 | 8   | 288.78   | 2023-12-18T09:57:37Z |

z-score


#### Back {#back}

The number of standard deviations a value is above, or below, the mean. The difference between a value and the mean as a multiple of the standard deviation.


#### Source {#source}

(<a href="#citeproc_bib_item_38">“Standard Score” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 491.39   | 2024-09-02T00:03:34Z |
| 1        | 2.80 | 8   | 302.86   | 2023-12-29T00:45:23Z |

-   {{\\(\bar{x}\\)}@0}

{{Sample mean}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_33">“Sample Mean and Covariance” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 9   | 423.26   | 2024-08-22T22:21:00Z |

-   {{\\(\mu\\)}@0}

Population mean


#### Source {#source}

(<a href="#citeproc_bib_item_21">“Mean” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 452.30   | 2024-06-16T21:10:17Z |
| 1        | 2.50 | 8   | 308.02   | 2023-12-22T15:22:36Z |

-   {{\\(\operatorname{cov}(X, Y)\\)}@0}

{{The covariance of the random variable \\(X\\) with respect to the random variable \\(Y\\).}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_14">“Covariance” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 8   | 338.75   | 2024-02-24T07:52:29Z |
| 1        | 2.65 | 8   | 295.52   | 2023-12-30T15:43:01Z |

-   {{\\(\operatorname{var}(X)\\)}@0}

{{The variance of a random variable, \\(X\\)}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_42">“Variance” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 1.90 | 8   | 130.36   | 2023-10-31T09:52:21Z |

-   {{\\(s^2\\)}@0}

Sample variance


#### Source {#source}

(<a href="#citeproc_bib_item_36">“Standard Deviation” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 366.04   | 2024-04-02T17:50:31Z |

-   {{\\(\sigma^2\\)}@0}

Population variance


#### Source {#source}

(<a href="#citeproc_bib_item_36">“Standard Deviation” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 309.52   | 2023-12-03T02:41:15Z |
| 1        | 2.50 | 8   | 305.47   | 2024-01-04T02:13:36Z |

-   {{\\(\text{H}\_0\\)}@0}

{{Null hypothesis}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_25">“Null Hypothesis” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.80 | 8   | 322.58   | 2024-01-13T17:48:02Z |
| 1        | 2.50 | 9   | 393.35   | 2024-07-09T01:35:46Z |
| 2        | 2.65 | 8   | 333.18   | 2024-02-14T17:47:38Z |

-   {{\\(\text{H}\_a\\)}@0}
-   {{\\(\text{H}\_1\\)}@1}

{{Alternative hypothesis}@2}


#### Source {#source}

(<a href="#citeproc_bib_item_1">“Alternative Hypothesis” 2022</a>)


### Describe {#describe}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.80 | 8   | 262.72   | 2023-09-22T08:41:47Z |
| back     | 2.35 | 7   | 116.78   | 2023-06-25T22:54:08Z |

Bias-variance tradeoff


#### Back {#back}

The conflict of trying to simultaneously reduce both the bias and the variance of a statistical model. The bias and the variance are inversely related.


#### Source {#source}

(<a href="#citeproc_bib_item_7">“Bias Variance Tradeoff” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.15 | 8   | 241.44   | 2024-02-15T00:48:00Z |
| front    | 2.65 | 12  | 301.94   | 2024-01-01T15:52:32Z |

Deviation


#### Back {#back}

A measure of difference between the observed value of a variable and some other value, often the variable's mean.


#### Source {#source}

(<a href="#citeproc_bib_item_15">“Deviation (Statistics)” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.35 | 9   | 554.21   | 2025-01-27T08:36:45Z |
| front    | 2.35 | 5   | 31.29    | 2023-04-03T20:45:56Z |

Event space of a probability space


#### Back {#back}

A set of events, \\(\mathcal{F}\\); an event being a set of outcomes in the sample space. A set of subsets of the sample space, \\(\Omega\\), called events.


#### Extra {#extra}

Eg: A d6 would have an event space: \\(\\{\\{1\\}, ..., \\{6\\}, \\{1, 3, 5\\}, ...\\}\\)


#### Source {#source}

(<a href="#citeproc_bib_item_29">“Probability Space” 2022</a>)


### Definition (Statistics, Machine Learning) {#definition--statistics-machine-learning}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 9   | 537.27   | 2024-12-12T19:48:38Z |
| front    | 2.65 | 9   | 370.02   | 2024-03-23T18:15:35Z |

Linear model


#### Back {#back}

A model which can be written as a linear equation


#### Extra {#extra}

\\(\hat{f}(X) = \beta\_0 + \beta\_1X\_1 + \cdots + \beta\_nX\_n\\)


#### Source {#source}


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 1.60 | 8   | 72.61    | 2023-09-04T04:38:12Z |
| front    | 2.50 | 9   | 276.71   | 2023-10-15T07:30:05Z |

Mean squared error


#### Back {#back}

\\(\frac{1}{n}\sum^{n}\_{i=1}(y\_i - \hat{f}(x\_i))^2\\)


#### Extra {#extra}

\\(\frac{1}{n}a^Ta \\; | \\; a = Y - \hat{Y}\\)


#### Source {#source}

(<a href="#citeproc_bib_item_18">James et al. 2013</a>)


### Definition (Statistics, ML) {#definition--statistics-ml}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 1.90 | 5   | 22.91    | 2023-08-11T11:24:55Z |
| front    | 2.65 | 8   | 357.47   | 2024-03-02T16:28:39Z |

Non-parametric model


#### Back {#back}

A model for which the number of parameters depends on the training data; often more data implies more parameters.


#### Source {#source}

(<a href="#citeproc_bib_item_23">“Nonparametric Statistics” 2022</a>)


### Definition {#definition}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.35 | 8   | 295.89   | 2023-12-29T14:48:53Z |
| front    | 2.65 | 8   | 261.62   | 2023-09-07T07:12:45Z |

Null hypothesis


#### Back {#back}

The default assumption; that a quantity to be measured is zero/null.


#### Source {#source}

(<a href="#citeproc_bib_item_25">“Null Hypothesis” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.35 | 12  | 433.06   | 2024-08-11T16:09:45Z |
| front    | 2.50 | 9   | 403.92   | 2024-07-27T18:24:50Z |

Overfitting


#### Back {#back}

A descriptor of a model that contains more parameters than can be justified by the data; it has unknowingly extracted some of the residual variation (ie the noise) as if that variation represented the underlying model structure. The production of an analysis that corresponds too closely to a particular set of data, and may therefore fail to fit additional data or predict future observations.


#### Source {#source}

(<a href="#citeproc_bib_item_26">“Overfitting” 2022</a>)


### Definition (Statistics, ML) {#definition--statistics-ml}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 9   | 375.49   | 2024-03-19T14:53:06Z |
| front    | 2.80 | 9   | 302.16   | 2023-12-11T21:21:56Z |

Parametric model


#### Back {#back}

A finite-dimensional model whose parameters encode all the information about its predictions.


#### Source {#source}

(<a href="#citeproc_bib_item_27">“Parametric Model” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 14  | 524.13   | 2024-10-29T23:27:23Z |
| front    | 2.50 | 6   | 116.17   | 2023-05-11T20:26:33Z |

Probability distribution


#### Back {#back}

The probability function of a probability space. The mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. It is a mathematical description of a random phenomenon in terms of its sample space and the probabilities of events.


#### Source {#source}

(<a href="#citeproc_bib_item_28">“Probability Distribution” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.50 | 8   | 281.26   | 2023-11-25T09:46:57Z |
| front    | 2.35 | 1   | 1.00     | 2023-05-26T14:14:21Z |

Probability function


#### Back {#back}

A function which assigns each event in \\(\mathcal{F}\\) a probability \\([0, 1]\\).


#### Source {#source}

(<a href="#citeproc_bib_item_29">“Probability Space” 2022</a>)


### Definition {#definition}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 1.30 | 10  | 36.70    | 2023-08-08T18:02:41Z |
| front    | 2.65 | 6   | 128.22   | 2023-07-04T21:34:06Z |

Probability space


#### Back {#back}

A mathematical construct that provides a formal model of a random process or "experiment"


#### Source {#source}

(<a href="#citeproc_bib_item_29">“Probability Space” 2022</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 13  | 398.60   | 2024-07-02T06:18:19Z |
| 1        | 2.35 | 1   | 1.00     | 2023-07-15T13:21:07Z |

-   {{Correlation}@0}
-   {{Dependence}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_13">“Correlation” 2022</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 8   | 287.22   | 2023-11-09T20:05:32Z |
| 1        | 2.65 | 8   | 238.20   | 2023-08-24T22:21:21Z |

-   {{Inverse relationship}@0}
-   {{Negative relationship}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_22">“Negative Relationship” 2021</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.60 | 15  | 253.91   | 2023-09-26T14:06:09Z |
| 1        | 1.90 | 7   | 109.35   | 2023-07-15T00:43:52Z |

-   {{Non-parametric model}@0}
-   {{Infinite-dimensional model}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_17">Ghahramani, n.d.</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 311.83   | 2024-01-14T13:19:14Z |
| 1        | 2.35 | 7   | 142.22   | 2023-04-01T21:44:28Z |

-   {{Parametric model}@0}
-   {{Finite-dimensional model}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_27">“Parametric Model” 2022</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.60 | 12  | 428.38   | 2024-07-27T23:38:20Z |
| 1        | 2.50 | 8   | 270.04   | 2023-10-02T16:18:43Z |

-   {{Qualitative}@0}
-   {{Categorical}@1}


#### Source {#source}


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 9   | 427.19   | 2024-05-26T17:53:25Z |
| 1        | 2.65 | 8   | 365.05   | 2024-05-02T17:01:08Z |
| 2        | 2.65 | 8   | 335.05   | 2024-05-25T18:35:52Z |

-   {{Residual sum of squares (RSS)}@0}
-   {{Sum of squared error (SSE)}@1}
-   {{Sum of squared residuals (SSR)}@2}


#### Source {#source}

(<a href="#citeproc_bib_item_31">“Residual Sum of Squares” 2022</a>)


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.80 | 8   | 269.09   | 2023-10-02T16:38:49Z |
| 1        | 2.80 | 8   | 320.79   | 2023-12-08T09:17:36Z |

-   {{Standard error of \\(\hat{\mu}\\)}@0}
-   {{\\(\operatorname{SE}(\hat{\mu})\\)}@1}


#### Source {#source}


### AKA {#aka}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 9   | 357.16   | 2024-03-03T04:12:39Z |
| 1        | 2.80 | 8   | 264.26   | 2023-10-08T08:22:43Z |
| 2        | 2.50 | 12  | 173.06   | 2023-06-07T19:33:16Z |

-   {{z-score}@0}
-   {{Standard score}@1}
-   {{Normal score}@2}


#### Source {#source}

(<a href="#citeproc_bib_item_38">“Standard Score” 2022</a>)


### Compare and contrast {#compare-and-contrast}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| front    | 2.15 | 6   | 51.78    | 2023-04-10T10:06:15Z |

Covariance and correlation


#### Back {#back}

-   Covariance and correlation both indicate a relationship between two variables; that is, a positive or inverse relationship.
-   Correlation, unlike covariance, additionally communicates the degree of that relationship -- how much one variable changes given a change in the other.


#### Source {#source}

(<a href="#citeproc_bib_item_8">Botha 2018</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.50 | 8   | 372.94   | 2024-03-08T02:45:21Z |
| front    | 2.65 | 8   | 329.70   | 2024-02-03T22:04:00Z |

Alternative hypothesis


#### Back {#back}

A position that states that something is happening; that the quantity being measured is non-zero.


#### Source {#source}

(<a href="#citeproc_bib_item_1">“Alternative Hypothesis” 2022</a>)


### Definition {#definition}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.50 | 9   | 461.92   | 2024-09-10T12:44:37Z |
| front    | 2.65 | 9   | 596.94   | 2025-02-17T12:37:49Z |

Bayes error rate


#### Back {#back}

The lowest possible error rate for any classifier; analogous to the irreducible error.


#### Source {#source}

(<a href="#citeproc_bib_item_4">“Bayes Error Rate” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 8   | 381.93   | 2024-03-27T03:52:00Z |
| front    | 2.65 | 8   | 337.68   | 2024-02-26T11:34:28Z |

Bessel's correction


#### Back {#back}

The use of \\(n-1\\) in place of \\(n\\) in the formula for the sample variance and the sample standard deviation.


#### Extra {#extra}

\\(s^2 =\\) \\(\frac{1}{n-1} \sum\_{i = 1}^n (x\_i - \bar{x})^2\\)


#### Source {#source}

(<a href="#citeproc_bib_item_5">“Bessel’s Correction” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 2.65 | 9   | 443.38   | 2024-06-18T06:15:48Z |
| front    | 2.35 | 9   | 465.10   | 2024-10-17T17:57:45Z |

Bias


#### Back {#back}

The difference between an estimator's expected value and the true value of the parameter being estimated.


#### Source {#source}

(<a href="#citeproc_bib_item_6">“Bias of an Estimator” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 1.60 | 7   | 50.25    | 2023-09-05T19:49:30Z |
| front    | 2.35 | 6   | 75.13    | 2023-04-23T00:36:10Z |

Correlation


#### Back {#back}

Any statistical relationship, whether causal or not, between two random variables or bivariate data.


#### Source {#source}

(<a href="#citeproc_bib_item_13">“Correlation” 2022</a>)


### Definition (Statistics) {#definition--statistics}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| back     | 1.30 | 6   | 11.51    | 2023-07-30T01:48:40Z |
| front    | 1.60 | 7   | 54.66    | 2023-05-07T06:44:21Z |

Covariance


#### Back {#back}

-   The joint variability of two random variables.
-   Measures how two random variables in a data set will change together. That is, a positive [...] implies that the second will also increase when the first increases.


#### Source {#source}

(<a href="#citeproc_bib_item_14">“Covariance” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 8   | 343.95   | 2024-02-26T16:31:49Z |
| 1        | 2.65 | 8   | 333.24   | 2024-01-30T19:38:02Z |

-   {{\\(\operatorname{P}(A)\\)}@0}

{{Probability of \\(A\\)}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_24">“Notation in Probability and Statistics” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.65 | 8   | 373.57   | 2024-04-21T02:27:59Z |
| 1        | 2.65 | 8   | 230.88   | 2023-07-19T13:18:14Z |

-   {{\\(\operatorname{P}(A|B)\\)}@0}

{{Conditional probability of \\(A\\), given \\(B\\).}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_11">“Conditional Probability” 2022</a>)


### Denotes {#denotes}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.35 | 9   | 439.82   | 2024-08-26T10:29:11Z |
| 1        | 2.35 | 8   | 347.37   | 2024-06-23T21:43:43Z |

-   {{\\(\operatorname{P}(\neg A)\\)}@0}

{{Probability of not-\\(A\\)}@1}


#### Source {#source}

(<a href="#citeproc_bib_item_24">“Notation in Probability and Statistics” 2022</a>)


### {{\\(\operatorname{P}(A \cap B)\\)}@0} \\(=\\) {{\\(\operatorname{P}(A) \operatorname{P}(B | A)\\)}{terms of A}@1} {#operatorname-p--a-cap-b--0-operatorname-p--a--operatorname-p--b-a--terms-of-a-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 7   | 329.96   | 2024-04-13T15:19:37Z |
| 1        | 2.20 | 7   | 175.58   | 2023-07-24T16:15:29Z |


#### Source {#source}

(<a href="#citeproc_bib_item_20">“Law of Total Probability” 2022</a>)


### {{\\(\operatorname{P}(A \cap B)\\)}@0} \\(=\\) {{\\(\operatorname{P}(B) \operatorname{P}(A | B)\\)}{terms of B}@1} {#operatorname-p--a-cap-b--0-operatorname-p--b--operatorname-p--a-b--terms-of-b-1}

| position | ease | box | interval | due                  |
|----------|------|-----|----------|----------------------|
| 0        | 2.50 | 7   | 346.15   | 2024-02-17T21:00:16Z |
| 1        | 2.35 | 1   | 1.00     | 2023-07-21T15:25:04Z |


#### Source {#source}

(<a href="#citeproc_bib_item_20">“Law of Total Probability” 2022</a>)

## References

<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>“Alternative Hypothesis.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Alternative_hypothesis&oldid=1122934976">https://en.wikipedia.org/w/index.php?title=Alternative_hypothesis&#38;oldid=1122934976</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>“Asymptote.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Asymptote&oldid=1120501401">https://en.wikipedia.org/w/index.php?title=Asymptote&#38;oldid=1120501401</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>“Base Rate.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Base_rate&oldid=1129991876">https://en.wikipedia.org/w/index.php?title=Base_rate&#38;oldid=1129991876</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>“Bayes Error Rate.” 2022. <i>Wikipedia</i>, October. <a href="https://en.wikipedia.org/w/index.php?title=Bayes_error_rate&oldid=1118554846">https://en.wikipedia.org/w/index.php?title=Bayes_error_rate&#38;oldid=1118554846</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>“Bessel’s Correction.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Bessel%27s_correction&oldid=1121897104">https://en.wikipedia.org/w/index.php?title=Bessel%27s_correction&#38;oldid=1121897104</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>“Bias of an Estimator.” 2022. <i>Wikipedia</i>, September. <a href="https://en.wikipedia.org/w/index.php?title=Bias_of_an_estimator&oldid=1110965892">https://en.wikipedia.org/w/index.php?title=Bias_of_an_estimator&#38;oldid=1110965892</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>“Bias Variance Tradeoff.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Bias%E2%80%93variance_tradeoff&oldid=1127464046">https://en.wikipedia.org/w/index.php?title=Bias%E2%80%93variance_tradeoff&#38;oldid=1127464046</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>Botha, Martinette. 2018. “An Introduction to Variance, Covariance &#38; Correlation | Alchemer Blog.” <i>Alchemer</i>. <a href="https://www.alchemer.com/resources/blog/variance-covariance-correlation/">https://www.alchemer.com/resources/blog/variance-covariance-correlation/</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_9"></a>Boyd, Stephen P., and Lieven Vandenberghe. 2018. <i>Introduction to Applied Linear Algebra: Vectors, Matrices, and Least Squares</i>. Cambridge, UK ; New York, NY: Cambridge University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_10"></a>“Cluster Analysis.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Cluster_analysis&oldid=1127979524">https://en.wikipedia.org/w/index.php?title=Cluster_analysis&#38;oldid=1127979524</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_11"></a>“Conditional Probability.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Conditional_probability&oldid=1126421689">https://en.wikipedia.org/w/index.php?title=Conditional_probability&#38;oldid=1126421689</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_12"></a>“Confusion Matrix.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Confusion_matrix&oldid=1127656922">https://en.wikipedia.org/w/index.php?title=Confusion_matrix&#38;oldid=1127656922</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_13"></a>“Correlation.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Correlation&oldid=1123244609">https://en.wikipedia.org/w/index.php?title=Correlation&#38;oldid=1123244609</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_14"></a>“Covariance.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Covariance&oldid=1130091539">https://en.wikipedia.org/w/index.php?title=Covariance&#38;oldid=1130091539</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_15"></a>“Deviation (Statistics).” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Deviation_(statistics)&oldid=1121693971">https://en.wikipedia.org/w/index.php?title=Deviation_(statistics)&#38;oldid=1121693971</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_16"></a>“Expected Value.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Expected_value&oldid=1124470444">https://en.wikipedia.org/w/index.php?title=Expected_value&#38;oldid=1124470444</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_17"></a>Ghahramani, Zoubin. n.d. “Parametric Vs Nonparametric Models.” <a href="http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf">http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_18"></a>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani, eds. 2013. <i>An Introduction to Statistical Learning: With Applications in R</i>. Springer Texts in Statistics 103. New York: Springer.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_19"></a>“K-Means Clustering.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=K-means_clustering&oldid=1127979478">https://en.wikipedia.org/w/index.php?title=K-means_clustering&#38;oldid=1127979478</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_20"></a>“Law of Total Probability.” 2022. <i>Wikipedia</i>, September. <a href="https://en.wikipedia.org/w/index.php?title=Law_of_total_probability&oldid=1108554328">https://en.wikipedia.org/w/index.php?title=Law_of_total_probability&#38;oldid=1108554328</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_21"></a>“Mean.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Mean&oldid=1127179090">https://en.wikipedia.org/w/index.php?title=Mean&#38;oldid=1127179090</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_22"></a>“Negative Relationship.” 2021. <i>Wikipedia</i>, August. <a href="https://en.wikipedia.org/w/index.php?title=Negative_relationship&oldid=1040328243">https://en.wikipedia.org/w/index.php?title=Negative_relationship&#38;oldid=1040328243</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_23"></a>“Nonparametric Statistics.” 2022. <i>Wikipedia</i>, October. <a href="https://en.wikipedia.org/w/index.php?title=Nonparametric_statistics&oldid=1116249193">https://en.wikipedia.org/w/index.php?title=Nonparametric_statistics&#38;oldid=1116249193</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_24"></a>“Notation in Probability and Statistics.” 2022. <i>Wikipedia</i>, August. <a href="https://en.wikipedia.org/w/index.php?title=Notation_in_probability_and_statistics&oldid=1106855377">https://en.wikipedia.org/w/index.php?title=Notation_in_probability_and_statistics&#38;oldid=1106855377</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_25"></a>“Null Hypothesis.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Null_hypothesis&oldid=1127357527">https://en.wikipedia.org/w/index.php?title=Null_hypothesis&#38;oldid=1127357527</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_26"></a>“Overfitting.” 2022. <i>Wikipedia</i>, October. <a href="https://en.wikipedia.org/w/index.php?title=Overfitting&oldid=1115154474">https://en.wikipedia.org/w/index.php?title=Overfitting&#38;oldid=1115154474</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_27"></a>“Parametric Model.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Parametric_model&oldid=1124648295">https://en.wikipedia.org/w/index.php?title=Parametric_model&#38;oldid=1124648295</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_28"></a>“Probability Distribution.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Probability_distribution&oldid=1127805728">https://en.wikipedia.org/w/index.php?title=Probability_distribution&#38;oldid=1127805728</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_29"></a>“Probability Space.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Probability_space&oldid=1122072139">https://en.wikipedia.org/w/index.php?title=Probability_space&#38;oldid=1122072139</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_30"></a>“Random Variable.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Random_variable&oldid=1124246530">https://en.wikipedia.org/w/index.php?title=Random_variable&#38;oldid=1124246530</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_31"></a>“Residual Sum of Squares.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Residual_sum_of_squares&oldid=1127927489">https://en.wikipedia.org/w/index.php?title=Residual_sum_of_squares&#38;oldid=1127927489</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_32"></a>“Root Mean Square.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Root_mean_square&oldid=1127312985">https://en.wikipedia.org/w/index.php?title=Root_mean_square&#38;oldid=1127312985</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_33"></a>“Sample Mean and Covariance.” 2022. <i>Wikipedia</i>, January. <a href="https://en.wikipedia.org/w/index.php?title=Sample_mean_and_covariance&oldid=1063504049">https://en.wikipedia.org/w/index.php?title=Sample_mean_and_covariance&#38;oldid=1063504049</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_34"></a>“Sampling Distribution.” 2022. <i>Wikipedia</i>, July. <a href="https://en.wikipedia.org/w/index.php?title=Sampling_distribution&oldid=1099367574">https://en.wikipedia.org/w/index.php?title=Sampling_distribution&#38;oldid=1099367574</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_35"></a>“Simple Linear Regression.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Simple_linear_regression&oldid=1126138325">https://en.wikipedia.org/w/index.php?title=Simple_linear_regression&#38;oldid=1126138325</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_36"></a>“Standard Deviation.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Standard_deviation&oldid=1120954441">https://en.wikipedia.org/w/index.php?title=Standard_deviation&#38;oldid=1120954441</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_37"></a>“Standard Error.” 2022. <i>Wikipedia</i>, October. <a href="https://en.wikipedia.org/w/index.php?title=Standard_error&oldid=1113740881">https://en.wikipedia.org/w/index.php?title=Standard_error&#38;oldid=1113740881</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_38"></a>“Standard Score.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Standard_score&oldid=1128321544">https://en.wikipedia.org/w/index.php?title=Standard_score&#38;oldid=1128321544</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_39"></a>“Statistic.” 2022. <i>Wikipedia</i>, August. <a href="https://en.wikipedia.org/w/index.php?title=Statistic&oldid=1103199673">https://en.wikipedia.org/w/index.php?title=Statistic&#38;oldid=1103199673</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_40"></a>“Stochastic.” 2022. <i>Wikipedia</i>, November. <a href="https://en.wikipedia.org/w/index.php?title=Stochastic&oldid=1123248560">https://en.wikipedia.org/w/index.php?title=Stochastic&#38;oldid=1123248560</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_41"></a>“Time Series.” 2022. <i>Wikipedia</i>, December. <a href="https://en.wikipedia.org/w/index.php?title=Time_series&oldid=1126209544">https://en.wikipedia.org/w/index.php?title=Time_series&#38;oldid=1126209544</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_42"></a>“Variance.” 2022. <i>Wikipedia</i>, October. <a href="https://en.wikipedia.org/w/index.php?title=Variance&oldid=1117946674">https://en.wikipedia.org/w/index.php?title=Variance&#38;oldid=1117946674</a>.</div>
</div>
